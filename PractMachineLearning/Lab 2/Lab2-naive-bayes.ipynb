{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UisOuoIAXgT6"
   },
   "source": [
    "# Practical Machine Learning\n",
    "# Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEn9Vd26XgT8"
   },
   "source": [
    "## Naive Bayes\n",
    "\n",
    "We are going to classify the MNIST data using the Naive Bayes classifier using the **scikit-learn** library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTjAqTKlXgT8"
   },
   "source": [
    "## Bayes' theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILstAW8VXgT9"
   },
   "source": [
    "![bayes_rule.png](attachment:bayes_rule.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WuBdJ5xbXgT-"
   },
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Naives Bayes method is a supervised learning algorithm based on applying Bayes' theorem with the '*naive*' assumption of conditional independence between every pair of features given the value of the class variable.\n",
    "\n",
    "Let *X* be a feature vector $X=\\{x_1, x_2,..., x_n\\}$ and $y_k$ be a class variable, the predicted label ($y_{hat}$) is:\n",
    "$$y_{hat} = argmax_{y_k} P(y_k) \\prod_{i=1}^{i=n}P(x_i | y_k) $$\n",
    "where $P(y_k)$ is the likelihood of class $y_k$ and $P(x_i | y_k)$ is the likelihood of feature $x_i$ in class $y_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQfa0JDCXgT_"
   },
   "source": [
    "### Gaussian Naive Bayes\n",
    "\n",
    "The likelihood of the features is assumed to be Gaussian:\n",
    "$$P(x_i | y_k) = \\frac{1}{\\sqrt{2\\pi \\sigma^2_{y_k}}} exp(- \\frac{x_i - \\mu_{y_k}}{2\\sigma^2_{y_k}}) $$\n",
    "\n",
    "where $\\sigma_{y_k} $ and $\\mu_{y_k}$ are estimated using maximum likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fAc7EtyXgT_"
   },
   "source": [
    "### Multinomial Naive Bayes\n",
    "\n",
    "It is used for multinomially distributed data and $P(x_i | y_k)$ is the probability of feature $i$ appearing in a sample belonging to class $y_k$.\n",
    "\n",
    "\n",
    "$$P(x_i | y_k) = \\frac{number-of-examples-in-class-y_k-that-have-x_i}{number-of-examples-in-class-y_k}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EpyZVEkJXgUA"
   },
   "source": [
    "## How to use scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wzd9zlv_XgUB"
   },
   "outputs": [],
   "source": [
    "# import the library\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NPPjiRY8XgUE"
   },
   "source": [
    "##### define the model\n",
    "model = KNeighborsClassifier(n_neighbors=7, metric='minkowski') \n",
    "\n",
    "##### train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "##### predict the labels\n",
    "predicted_labels = model.predict(X_test)\n",
    "\n",
    "##### compute the accuracy\n",
    "accuracy = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ijsH9caAXgUF"
   },
   "source": [
    "# Execises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJF-5PlgXgUG"
   },
   "source": [
    "### 1. Compute the accuracy of the multinomial naive bayes classifier on the MNIST subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T18:29:33.961251Z",
     "start_time": "2023-10-25T18:29:33.896389Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lF9AnysVXgUG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Naive Bayes on the MNIST subset: 84.60%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "train_images = np.load('data/train_images.npy')\n",
    "train_labels = np.load('data/train_labels.npy')\n",
    "test_images = np.load('data/test_images.npy')\n",
    "test_labels = np.load('data/test_labels.npy')\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "model.fit(train_images, train_labels)\n",
    "\n",
    "model.predict([test_images[0]])\n",
    "# Predict the labels of the test data\n",
    "predicted_labels = model.predict(test_images)\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(f\"Accuracy of Multinomial Naive Bayes on the MNIST subset: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab2-naive-bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
